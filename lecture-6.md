---
title: Generative AI and Editorial Quality
link-citations: true
author: Heinz Wittenbrink
date: 2026-01-20
theme: white
---

#

<style>

    #refs

    div {font-size: small;}

    section#footnotes p  {font-size: small;}


    
</style>

# Intro

* No technophobia
* Different work and life situations
* Limited knowledge

# Problems not sufficiently mentioned here

* Resource use / ecology [@costaIntelligenceArtificielleVrai2025]
* Techfascism ([Refusing Tech Fascism](https://error417.expectation.fail/406/tech-fascism-not-acceptable/essay-refusing-tech-fascism-by-tante "R𰁉𰁠𰆒𰅸𰂈𰄱𰁩 𰆄𰁇C𰂀 𰁡𰀁𰅴𰀥𰂆SM") @geuterRefusingTechFascism2025)
* Intellectual property

# Goals

* Exchange of experience
* AI and editorial tasks
* Trade-offs and risks
* Standards and guidelines for the use of AI

# Use cases

# Example

  [ChatGPT Protocol](ai-material.pdf)

# What is generative AI?

* Large Language Models and Machine Learnings
* Chatbots and other applications

# Affordances and limits of generative AI

* "Stochastic parrots" [@benderDangersStochasticParrots2021]
* Enormous capacity of predicting tokens
* Base: Models of (written) documents in natural languages
* No knowledge representation (up to now in mainstream apps)

# Use in editorial contexts

* Check for compliance with standards: [Make your writing standards … standard - Acrolinx](https://www.acrolinx.com/ "Make your writing standards … standard - Acrolinx"), [Case Studies Archive - Acrolinx](https://www.acrolinx.com/case-studies/ "Case Studies Archive - Acrolinx")
* Versions for different audiences: [Graphical Storytelling](https://www.bbc.co.uk/rdnewslabs/projects/graphical-storytelling "Graphical Storytelling") [@caswellAudiencesAutomationAI2024]
* Automatic writing: [Writing with AI | OpenAI](https://openai.com/chatgpt/use-cases/writing-with-ai/ "Writing with AI | OpenAI")

# 
  
* Reseach in large amounts of documents: [Panama-Papers: "Wir wären ohne die Technologie nie so weit gekommen." | MDR.DE](https://www.mdr.de/medien360g/medienwissen/interview-ki-munzinger-102.html "Panama-Papers: "Wir wären ohne die Technologie nie so weit gekommen." | MDR.DE") [@heesenKunstlicheIntelligenzIm2023]
* Extracting relationships and knowledge: [Analyzing the Panama Papers with Neo4j: Data Models, Queries & More](https://neo4j.com/blog/analyzing-panama-papers-neo4j/ "Analyzing the Panama Papers with Neo4j: Data Models, Queries & More")

# Generative AI and intelligence

* Fact checking is interactive and social
* Differences between generative AI and human intelligence
* Generated texts (and images) are never reliable

# The bullshit problem

> It is just this lack of connection to a concern with truth this indifference to how things really are — that I regard as of the  essence of bullshit.
 [frankfurtBullshit2013]


# 

> Bullshit is unavoidable whenever circumstances require  someone to talk without knowing what he is talking about.  [frankfurtBullshit2013]

# Hallucinations

* [What Are AI Hallucinations and Why Do They Happen?](https://www.sciencenewstoday.org/what-are-ai-hallucinations-and-why-do-they-happen "What Are AI Hallucinations and Why Do They Happen?") [@tuhinWhatAreAI2025]

> Unlike a computer bug—which is a result of faulty code—an AI hallucination stems from the nature of how the AI generates text. It is not a glitch. It’s a byproduct of prediction. The model isn’t trying to lie; it’s simply guessing what the next part of the response should be, and sometimes, that guess is wrong.


# Basic multiplication and keeping track

[Why Can’t Powerful LLMs Learn Multiplication?](https://datascience.uchicago.edu/insights/why-cant-powerful-llms-learn-multiplication/ "Why Can’t Powerful LLMs Learn Multiplication? | DSI") [@universityofchicagoWhyCantPowerful2025]

> “As AI is increasingly integrated into critical decision-making, it’s essential to understand its unique ways of learning and thinking,” said Tan. “Our research is trying to chart that terrain.”



# Conclusion

Generative AI can not replace the social processes which establish what is true. Editorial quality depends on the editorial teamwork. This teamwork can be enhanced, but it can and must not be replaced by generative AI. 

# Standards and guidelines

BBC: [Guidance: The use of Artificial Intelligence](https://www.bbc.co.uk/editorialguidelines/guidance/use-of-artificial-intelligence "Guidance: The use of Artificial Intelligence")

* Principles of impartiality, accuracy, fairness and privacy
* Transparency and accountability
* Human editorial oversight and approval
* External tools must be authorized
* No use for generating content

#

University of Oxford: [Guidelines on the use of generative AI in communications](https://communications.admin.ox.ac.uk/communications-resources/ai-guidance "Guidelines on the use of generative AI | Communications Hub")

* Priority for "human creativity, curiosity and judgement"
* Transparence to safeguard trustworthyness
* Limited supportive use of AI tools and supervision by humans
* Continuous learning to have the necessary skills

#

Harvard Business School [Marketing AI Guidelines | About](https://www.hbs.edu/about/campus-and-culture/policies/marketing-ai-guidelines "Marketing AI Guidelines | About")

* Risks: Inauthenticity, intellectual property, factual errors
* Human oversight
* Transparence via tags ("Created by AI")





# Sources
  